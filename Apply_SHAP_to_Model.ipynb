{"cells":[{"cell_type":"markdown","metadata":{"id":"4nrZ0wvYOwnu"},"source":["#Set up"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2343,"status":"ok","timestamp":1717138308838,"user":{"displayName":"백승렬","userId":"14086593896525903207"},"user_tz":-540},"id":"tvbwKi86OJbY","outputId":"d27697c8-4ec8-45ff-d1de-ba793f1d803a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wpylE9-dOzDB","executionInfo":{"status":"ok","timestamp":1717138323947,"user_tz":-540,"elapsed":15111,"user":{"displayName":"백승렬","userId":"14086593896525903207"}},"outputId":"86996c77-4aa9-4cfe-cb66-e986a48e7252"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in links: https://pytorch-geometric.com/whl/torch-2.2.1+cu121.html\n","Requirement already satisfied: torch-scatter==2.1.2 in /usr/local/lib/python3.10/dist-packages (2.1.2+pt22cu121)\n","Requirement already satisfied: torch-geometric in /usr/local/lib/python3.10/dist-packages (2.5.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.25.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.11.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2023.6.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.9.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.2.2)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.5.0)\n","Requirement already satisfied: shap in /usr/local/lib/python3.10/dist-packages (0.45.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from shap) (1.25.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from shap) (1.11.4)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from shap) (1.2.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from shap) (2.0.3)\n","Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.10/dist-packages (from shap) (4.66.4)\n","Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.10/dist-packages (from shap) (24.0)\n","Requirement already satisfied: slicer==0.0.8 in /usr/local/lib/python3.10/dist-packages (from shap) (0.0.8)\n","Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from shap) (0.58.1)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from shap) (2.2.1)\n","Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->shap) (0.41.1)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2024.1)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (3.5.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->shap) (1.16.0)\n"]}],"source":["!pip install torch-scatter==2.1.2 -f https://pytorch-geometric.com/whl/torch-2.2.1+cu121.html\n","!pip install torch-geometric\n","!pip install shap"]},{"cell_type":"markdown","metadata":{"id":"TPwHsMvyOn7N"},"source":["# Model"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"AcgFdmPSOi4b","executionInfo":{"status":"ok","timestamp":1717138325339,"user_tz":-540,"elapsed":1401,"user":{"displayName":"백승렬","userId":"14086593896525903207"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from torch.nn import Sequential as Seq, Linear as Lin, ReLU\n","from torch.nn import TransformerEncoderLayer, TransformerEncoder\n","from torch.nn.parameter import Parameter\n","from torch_scatter import scatter_mean\n","# from torch_geometric.nn import MetaLayer\n","\n","\n","TIME_WINDOW = 24\n","PRED_LEN = 6\n","\n","class Model(nn.Module):\n","    def __init__(self, mode, encoder, w_init, w, x_em, date_em, loc_em, edge_h, gnn_h, gnn_layer, city_num, group_num, pred_step, device):\n","        super(Model, self).__init__()\n","        self.device = device\n","        self.mode = mode\n","        self.encoder = encoder\n","        self.w_init = w_init\n","        self.x_em = x_em\n","        self.city_num = city_num\n","        self.group_num = group_num\n","        self.edge_h = edge_h\n","        self.gnn_layer = gnn_layer\n","        self.pred_step = pred_step\n","\n","        if self.encoder == 'self':\n","            self.encoder_layer = TransformerEncoderLayer(8, nhead=4, dim_feedforward=256)\n","            self.x_embed = Lin(TIME_WINDOW*8, x_em)\n","\n","        elif self.encoder == 'lstm':\n","            self.input_LSTM = nn.LSTM(8,x_em,num_layers=1,batch_first=True)\n","\n","\n","        if self.w_init == 'rand':\n","            self.w = Parameter(torch.randn(city_num,group_num).to(device,non_blocking=True),requires_grad=True)\n","\n","        elif self.w_init == 'group':\n","            self.w = Parameter(w,requires_grad=True)\n","\n","\n","        self.loc_embed = Lin(2, loc_em)\n","\n","        self.u_embed1 = nn.Embedding(12, date_em) #month\n","        self.u_embed2 = nn.Embedding(7, date_em) #week\n","        self.u_embed3 = nn.Embedding(24, date_em) #hour\n","\n","        self.edge_inf = Seq(Lin(x_em*2+date_em*3+loc_em*2,edge_h),ReLU(inplace=False))\n","\n","        self.group_gnn = nn.ModuleList([NodeModel(x_em+loc_em,edge_h,gnn_h)])\n","\n","        for i in range(self.gnn_layer-1):\n","            self.group_gnn.append(NodeModel(gnn_h,edge_h,gnn_h))\n","\n","        self.global_gnn = nn.ModuleList([NodeModel(x_em+gnn_h,1,gnn_h)])\n","\n","        for i in range(self.gnn_layer-1):\n","            self.global_gnn.append(NodeModel(gnn_h,1,gnn_h))\n","\n","        if self.mode == 'feedback':\n","            self.predMLP = Seq(Lin(gnn_h,16),ReLU(inplace=False),Lin(16,1),ReLU(inplace=False))\n","\n","        if self.mode == 'probe_x' or self.mode == 'probe_encoded' or self.mode == 'probe_woAttn':\n","            self.predMLP = Seq(Lin(gnn_h,16),ReLU(inplace=False),Lin(16,self.pred_step),ReLU(inplace=False))\n","            self.probe_gnn = nn.ModuleList([NodeModel(x_em,1,gnn_h)])\n","\n","            for i in range(self.gnn_layer-1):\n","                self.probe_gnn.append(NodeModel(gnn_h,1,gnn_h))\n","\n","        if self.mode == 'temp':\n","            self.decoder = DecoderModule(x_em,edge_h,gnn_h,gnn_layer,city_num,group_num,device)\n","            self.predMLP = Seq(Lin(gnn_h,16),ReLU(inplace=False),Lin(16,self.pred_step),ReLU(inplace=False))\n","            self.TemporalAggregateMLP = Seq(Lin(gnn_h+8,gnn_h),ReLU(inplace=False))\n","\n","        if self.mode == 'both':\n","            self.predMLP = Seq(Lin(gnn_h,16),ReLU(inplace=False),Lin(16,1),ReLU(inplace=False))\n","            self.TemporalAggregateMLP = Seq(Lin(gnn_h+8,gnn_h),ReLU(inplace=False))\n","\n","        if self.mode == 'feedbackDecoder':\n","            self.decoder = DecoderModule(x_em,edge_h,gnn_h,gnn_layer,city_num,group_num,device)\n","            self.predMLP = Seq(Lin(gnn_h,16),ReLU(inplace=False),Lin(16,1),ReLU(inplace=False))\n","\n","        if self.mode == 'baseline':\n","            self.decoder = DecoderModule(x_em,edge_h,gnn_h,gnn_layer,city_num,group_num,device)\n","            self.predMLP = Seq(Lin(gnn_h,16),ReLU(inplace=False),Lin(16,self.pred_step),ReLU(inplace=False))\n","\n","        if self.mode == 'final':\n","            self.x_embed = Lin(TIME_WINDOW*8, x_em)\n","\n","            self.predMLP = Seq(Lin(gnn_h,16),ReLU(inplace=False),Lin(16,self.pred_step),ReLU(inplace=False))\n","            self.global_gnn = nn.ModuleList([NodeModel(x_em,1,gnn_h)])\n","\n","            for i in range(self.gnn_layer-1):\n","                self.global_gnn.append(NodeModel(gnn_h,1,gnn_h))\n","\n","        elif self.mode == 'final2':\n","            self.encoder_layer = TransformerEncoderLayer(x_em, nhead=4, dim_feedforward=256, batch_first=True)\n","            self.x_embed = Lin(TIME_WINDOW*8, x_em)\n","\n","            self.predMLP = Seq(Lin(gnn_h,16),ReLU(inplace=False),Lin(16,self.pred_step),ReLU(inplace=False))\n","            self.global_gnn = nn.ModuleList([NodeModel(x_em,1,gnn_h)])\n","\n","            for i in range(self.gnn_layer-1):\n","                self.global_gnn.append(NodeModel(gnn_h,1,gnn_h))\n","\n","\n","    def batchInput(self, x, edge_w, edge_index):\n","        # new_x\n","        sta_num = x.shape[1]\n","        x = x.reshape(-1, x.shape[-1])\n","\n","        # edge_w\n","        edge_w = edge_w.reshape(-1,edge_w.shape[-1])\n","\n","        # edge_index\n","        for i in range(edge_index.size(0)):\n","            edge_index[i,:] = torch.add(edge_index[i,:], i*sta_num)\n","        edge_index = edge_index.transpose(0,1)\n","        edge_index = edge_index.reshape(2,-1)\n","\n","        return x, edge_w, edge_index\n","\n","\n","    def forward(self, x, u, edge_index, edge_w, loc):\n","        # Shape: (batch, 209, 24, 8)\n","        if self.mode == 'final':\n","            x = x.reshape(-1,self.city_num, TIME_WINDOW*x.shape[-1]) # Shape: (batch, 209, 24*8)\n","            x = self.x_embed(x) # Linear(24*8, x_em:32) Shape: (batch, 209, 32)\n","\n","            \"\"\" Update \"\"\"\n","            edge_w = edge_w.unsqueeze(dim=-1)\n","            new_x, edge_w, edge_index = self.batchInput(x, edge_w, edge_index)\n","            # new_x Shape: (batch, 209, 64) -> (batch*209, 64)\n","            # edge_w Shape: (batch, 4112) -> (batch*4112, 1)\n","            # edge_index Shape: (batch, 2, 4112) -> (2, batch*4112)\n","\n","            for i in range(self.gnn_layer):\n","                new_x = self.global_gnn[i](new_x, edge_index, edge_w) # Shape: (batch*209, 32)\n","\n","\n","            \"\"\" Final Forcasting \"\"\"\n","            res = self.predMLP(new_x)\n","            res = res.reshape(-1,self.city_num,self.pred_step) # Shape: (batch, 209, 6)\n","            return res\n","\n","        if self.mode == 'final2':\n","            x = x.reshape(-1,self.city_num, TIME_WINDOW*x.shape[-1]) # Shape: (batch, 209, 24*8)\n","            x = self.x_embed(x) # Linear(24*8, x_em:32) Shape: (batch, 209, 32)\n","            x = self.encoder_layer(x) # Shape: (batch, 209, 32)\n","\n","            \"\"\" Update \"\"\"\n","            edge_w = edge_w.unsqueeze(dim=-1)\n","            new_x, edge_w, edge_index = self.batchInput(x, edge_w, edge_index)\n","            # new_x Shape: (batch, 209, 64) -> (batch*209, 64)\n","            # edge_w Shape: (batch, 4112) -> (batch*4112, 1)\n","            # edge_index Shape: (batch, 2, 4112) -> (2, batch*4112)\n","\n","            for i in range(self.gnn_layer):\n","                new_x = self.global_gnn[i](new_x, edge_index, edge_w) # Shape: (batch*209, 32)\n","\n","\n","            \"\"\" Final Forcasting \"\"\"\n","            res = self.predMLP(new_x)\n","            res = res.reshape(-1,self.city_num,self.pred_step) # Shape: (batch, 209, 6)\n","\n","            return res\n","\n","\n","        if self.mode == 'probe_woAttn':\n","            x = x.reshape(-1,self.city_num, TIME_WINDOW*x.shape[-1]) # Shape: (batch, 209, 24*8)\n","            x = self.x_embed(x) # Linear(24*8, x_em:32) Shape: (batch, 209, 32)\n","\n","            \"\"\" Probe \"\"\"\n","            edge_w = edge_w.unsqueeze(dim=-1)\n","            new_x, edge_w, edge_index = self.batchInput(x, edge_w, edge_index)\n","            # new_x Shape: (batch, 209, 64) -> (batch*209, 64)\n","\n","            for i in range(self.gnn_layer):\n","                new_x = self.probe_gnn[i](new_x, edge_index, edge_w) # Shape: (batch*209, 32)\n","\n","            res = self.predMLP(new_x)\n","            res = res.reshape(-1,self.city_num,self.pred_step) # Shape: (batch, 209, 6)\n","\n","            return res\n","\n","\n","\n","        ''' Self Attention '''\n","        x = x.reshape(-1,x.shape[2],x.shape[3]) # Shape: (209*batch, 24, 8)\n","        x = x.transpose(0,1) # Shape: (24, batch*209, 8)\n","        x = self.encoder_layer(x) # self-attention, Shape: (24, batch*209, 8)\n","        x = x.transpose(0,1) # Shape: (batch*209, 24, 8)\n","\n","\n","        if self.mode == 'temp' or self.mode == 'both':\n","            x2 = x.reshape(-1,self.city_num,x.shape[1],x.shape[2]) # Temporal\n","            x2 = torch.index_select(x2, dim=2, index=torch.tensor([3, 7, 11, 15, 19, 23]).to(self.device)) ## ( batch size, num of city, selected 6h, 8features )\n","            x2 = x2.transpose(1,2) ## ( batch size, selected 6h , num of city, 8features ) [batch size, 6, 209, 8]\n","\n","            h_other5 = x2[:, :-1, :, :]  # [batch size, 5, 209, 8]\n","            h_other5 = h_other5.reshape(-1,h_other5.shape[1]*h_other5.shape[2],h_other5.shape[3])  # [batch size, 1045, 8]\n","\n","            h24 = x2[:, -1:, :, :]  # [batch size, 1, 209, 8]\n","            h24 = h24.reshape(-1,h24.shape[2],h24.shape[3]) # [batch size, 209, 8]\n","            h24 = h24.transpose(1,2)\n","\n","            attention_scores = torch.matmul(h_other5, h24)   # [batch size, 1045, 209]\n","            attention_scores = attention_scores.reshape(-1,5,209,attention_scores.shape[2])  # [batch size, 5, 209, 209]\n","            attention_weights = F.softmax(attention_scores, dim=1)  # [batch size, 5, 209, 209]\n","\n","            h_other5 = h_other5.reshape(-1,5,209,h_other5.shape[2]) # [batch size, 5, 209, 8]\n","            h_other5 = h_other5.transpose(2,3) # [batch size, 5, 8, 209]\n","\n","            attention_weighted_sum = torch.matmul(h_other5, attention_weights) # [batch size, 5, 8, 209]\n","            attention_weighted_sum = attention_weighted_sum.transpose(2,3)\n","            x2 = torch.sum(attention_weighted_sum, dim=1)  # [batch size, 209, 8]\n","\n","        x = x.reshape(-1,self.city_num, TIME_WINDOW*x.shape[-1]) # Shape: (batch, 209, 24*8)\n","        x = self.x_embed(x) # Linear(24*8, x_em:32) Shape: (batch, 209, 32)\n","\n","\n","        if self.mode == 'probe_x':\n","            \"\"\" Probe \"\"\"\n","            edge_w = edge_w.unsqueeze(dim=-1)\n","            new_x, edge_w, edge_index = self.batchInput(x, edge_w, edge_index)\n","            # new_x Shape: (batch, 209, 64) -> (batch*209, 64)\n","\n","            for i in range(self.gnn_layer):\n","                new_x = self.probe_gnn[i](new_x, edge_index, edge_w) # Shape: (batch*209, 32)\n","\n","            res = self.predMLP(new_x)\n","            res = res.reshape(-1,self.city_num,self.pred_step) # Shape: (batch, 209, 6)\n","\n","            return res\n","\n","\n","        ''' Differentiable grouping network\n","            City to City Group    '''\n","\n","        # S\n","        w = F.softmax(self.w, dim=1) # w: (209, group_num:15)\n","        w1 = w.transpose(0, 1)\n","        w1 = w1.unsqueeze(dim=0)\n","        w1 = w1.repeat_interleave(x.size(0), dim=0) # w1: (batch, group_num, 209)\n","\n","        # city group\n","        loc = self.loc_embed(loc) # Linear(2, loc_em:12), shape: (batch, 209, 12)\n","        x_loc = torch.cat([x,loc],dim=-1) # X, L (batch, 32+12=44)\n","        g_x = torch.bmm(w1,x_loc) # g_x: (batch, group_num, 44)\n","\n","\n","\n","        ''' Group Correlation Encoding Module\n","            Edge Connection '''\n","\n","        # T\n","        u_em1 = self.u_embed1(u[:,0]) # Embedding(12, date_em=4) Shape: (batch, 209, 4)\n","        u_em2 = self.u_embed2(u[:,1]) # Embedding(7, date_em=4)\n","        u_em3 = self.u_embed3(u[:,2]) # Embedding(24, date_em=4)\n","        u_em = torch.cat([u_em1,u_em2,u_em3],dim=-1) # Shape: (batch, 209, 12)\n","\n","        # Edge connection\n","        for i in range(self.group_num):\n","            for j in range(self.group_num):\n","                if i == j: continue\n","\n","                # ReLU(enc(Z_i, Z_j, T))\n","                g_edge_input = torch.cat([g_x[:,i],g_x[:,j],u_em],dim=-1) # Shape: (batch, 44+44+12=100)\n","                tmp_g_edge_w = self.edge_inf(g_edge_input) # Shape: (batch, 12)\n","\n","                tmp_g_edge_w = tmp_g_edge_w.unsqueeze(dim=0) # Shape: (1, batch, 209, 12)\n","                tmp_g_edge_index = torch.tensor([i,j]).unsqueeze(dim=0).to(self.device,non_blocking=True) # Shape: (1, 2)\n","\n","                if i == 0 and j == 1:\n","                    g_edge_w = tmp_g_edge_w # Shape: (1, batch, 12)\n","                    g_edge_index = tmp_g_edge_index # Shape: (1, 2)\n","                else:\n","                    g_edge_w = torch.cat([g_edge_w,tmp_g_edge_w],dim=0) # Shape: (210, batch, 12)\n","                    g_edge_index = torch.cat([g_edge_index,tmp_g_edge_index],dim=0) # Shape: (210, 2)\n","\n","\n","\n","\n","        ''' Group Message Passing\n","              Group Update '''\n","\n","        g_edge_w = g_edge_w.transpose(0,1)\n","        g_edge_index = g_edge_index.unsqueeze(dim=0)\n","        g_edge_index = g_edge_index.repeat_interleave(u_em.shape[0],dim=0)\n","        g_edge_index = g_edge_index.transpose(1,2)\n","        g_x, g_edge_w, g_edge_index = self.batchInput(g_x, g_edge_w, g_edge_index)\n","\n","        for i in range(self.gnn_layer):\n","            g_x = self.group_gnn[i](g_x,g_edge_index,g_edge_w)\n","\n","        g_x = g_x.reshape(-1,self.group_num,g_x.shape[-1])\n","\n","\n","\n","        ''' City Group to City '''\n","        # S\n","        w2 = w.unsqueeze(dim=0)\n","        w2 = w2.repeat_interleave(g_x.size(0), dim=0)\n","        new_x = torch.bmm(w2, g_x) # Shape: (batch, 209, 32)\n","\n","\n","        if self.mode == 'both':\n","            # x Shape: (batch:64, 209, 32)\n","\n","            \"\"\" City Update \"\"\"\n","            new_x_update = torch.cat([x,new_x],dim=-1)\n","            edge_w = edge_w.unsqueeze(dim=-1)\n","            tmp_edge_index = edge_index.clone()\n","            new_x_update, edge_w, tmp_edge_index = self.batchInput(new_x_update, edge_w, tmp_edge_index)\n","\n","            for i in range(self.gnn_layer):\n","                new_x_update = self.global_gnn[i](new_x_update,tmp_edge_index,edge_w)\n","\n","            \"\"\" Temporal \"\"\"\n","            x2 = x2.reshape(-1,x2.shape[-1])\n","            temp_x = torch.cat([x2, new_x_update],dim=-1)\n","            temp_x = self.TemporalAggregateMLP(temp_x)\n","            temp_x = temp_x.reshape(-1, self.city_num, temp_x.shape[-1])\n","\n","            for i in range(self.pred_step):\n","\n","                \"\"\" Feedback \"\"\"\n","                # x Shape: (batch, 209, 32)\n","                new_x = torch.cat([temp_x, new_x], dim=-1) # Shape: (batch, 209, 64)\n","\n","\n","                \"\"\" City Update \"\"\"\n","                tmp_edge_index = edge_index.clone()\n","                new_x, tmp_edge_w, tmp_edge_index = self.batchInput(new_x, edge_w, tmp_edge_index) # Shape: (batch*209, 64)\n","\n","                for j in range(self.gnn_layer):\n","                    new_x = self.global_gnn[j](new_x, tmp_edge_index, tmp_edge_w) # Shape: (batch*209, 32)\n","\n","\n","                \"\"\" Final Forcasting \"\"\"\n","                # new_x = self.decoder(new_x, self.w, g_edge_index, g_edge_w, tmp_edge_index, tmp_edge_w)\n","                tmp_res = self.predMLP(temp_x) # Shape: (batch*209, 1)\n","                tmp_res = tmp_res.reshape(-1, self.city_num) # Shape: (batch, 209)\n","                tmp_res = tmp_res.unsqueeze(dim=-1) # Shape: (batch, 209, 1)\n","                if i == 0:\n","                    res = tmp_res\n","                else:\n","                    res = torch.cat([res,tmp_res],dim=-1) # Shape: (batch, 209, i+1)\n","\n","                new_x = new_x.reshape(-1, self.city_num, self.x_em) # Shape: (batch, 209, 32)\n","\n","\n","        if self.mode == 'temp':\n","            \"\"\" City Update \"\"\"\n","            new_x = torch.cat([x,new_x],dim=-1)\n","            edge_w = edge_w.unsqueeze(dim=-1)\n","            new_x, edge_w, edge_index = self.batchInput(new_x, edge_w, edge_index)\n","\n","            for i in range(self.gnn_layer):\n","                new_x = self.global_gnn[i](new_x,edge_index,edge_w)\n","\n","            \"\"\" Temporal \"\"\"\n","            x2 = x2.reshape(-1,x2.shape[-1])\n","            new_x = torch.cat([x2,new_x],dim=-1)\n","            new_x = self.TemporalAggregateMLP(new_x)\n","\n","            \"\"\" Final Forcasting \"\"\"\n","            new_x = self.decoder(new_x, self.w, g_edge_index, g_edge_w, edge_index, edge_w) # Shape: (batch*209, 32)\n","            res = self.predMLP(new_x)\n","            res = res.reshape(-1,self.city_num,self.pred_step) # Shape: (batch, 209, 6)\n","\n","\n","        if self.mode == 'feedback':\n","            edge_w = edge_w.unsqueeze(dim=-1)\n","            output = x.reshape(-1, self.city_num, x.shape[-1])\n","\n","            for i in range(self.pred_step):\n","\n","                \"\"\" Feedback \"\"\"\n","                # x Shape: (batch, 209, 32)\n","                tmp_x = torch.cat([output, new_x], dim=-1) # Shape: (batch, 209, 64)\n","\n","\n","                \"\"\" City Update \"\"\"\n","                tmp_edge_index = edge_index.clone()\n","                tmp_x, tmp_edge_w, tmp_edge_index = self.batchInput(tmp_x, edge_w, tmp_edge_index) # Shape: (batch*209, 64)\n","                for j in range(self.gnn_layer):\n","                    tmp_x = self.global_gnn[j](tmp_x, tmp_edge_index, tmp_edge_w) # Shape: (batch*209, 32)\n","\n","\n","                \"\"\" Final Forcasting \"\"\"\n","                tmp_res = self.predMLP(tmp_x) # Shape: (batch*209, 1)\n","                tmp_res = tmp_res.reshape(-1, self.city_num) # Shape: (batch, 209)\n","                tmp_res = tmp_res.unsqueeze(dim=-1) # Shape: (batch, 209, 1)\n","                if i == 0:\n","                    res = tmp_res\n","                else:\n","                    res = torch.cat([res,tmp_res],dim=-1) # Shape: (batch, 209, i+1)\n","\n","                output = tmp_x.reshape(-1, self.city_num, self.x_em) # Shape: (batch, 209, 32)\n","\n","\n","\n","\n","        if self.mode == 'probe_encoded':\n","            \"\"\" City Update \"\"\"\n","            new_x = torch.cat([x,new_x],dim=-1) # Shape: (batch:64, 209, 64)\n","            edge_w = edge_w.unsqueeze(dim=-1)\n","            new_x, edge_w, edge_index = self.batchInput(new_x, edge_w, edge_index)\n","            # new_x Shape: (batch, 209, 64) -> (batch*209, 64)\n","            for i in range(self.gnn_layer):\n","                new_x = self.global_gnn[i](new_x, edge_index, edge_w) # Shape: (batch*209, 32)\n","\n","\n","            \"\"\" Probe \"\"\"\n","            new_x = new_x.reshape(-1, new_x.shape[-1])\n","\n","            for i in range(self.gnn_layer):\n","                new_x = self.probe_gnn[i](new_x, edge_index, edge_w) # Shape: (batch*209, 32)\n","\n","            res = self.predMLP(new_x)\n","            res = res.reshape(-1,self.city_num,self.pred_step) # Shape: (batch, 209, 6)\n","\n","            return res\n","\n","\n","        if self.mode == 'feedbackDecoder':\n","            \"\"\" City Update \"\"\"\n","            new_x = torch.cat([x,new_x],dim=-1) # Shape: (batch:64, 209, 64)\n","            edge_w = edge_w.unsqueeze(dim=-1)\n","            new_x, edge_w, edge_index = self.batchInput(new_x, edge_w, edge_index)\n","\n","            for i in range(self.gnn_layer):\n","                new_x = self.global_gnn[i](new_x,edge_index,edge_w)\n","\n","\n","            \"\"\" Final Forcasting \"\"\"\n","            for i in range(self.pred_step):\n","                new_x = self.decoder(new_x, self.w, g_edge_index, g_edge_w, edge_index, edge_w)\n","                tmp_res = self.predMLP(new_x)\n","                tmp_res = tmp_res.reshape(-1,self.city_num)\n","                tmp_res = tmp_res.unsqueeze(dim=-1)\n","                if i == 0:\n","                    res = tmp_res\n","                else:\n","                    res = torch.cat([res,tmp_res],dim=-1)\n","\n","\n","        if self.mode == 'baseline':\n","            \"\"\" City Update \"\"\"\n","            new_x = torch.cat([x,new_x],dim=-1) # Shape: (batch, 209, 64)\n","            edge_w = edge_w.unsqueeze(dim=-1)\n","            new_x, edge_w, edge_index = self.batchInput(new_x, edge_w, edge_index)\n","            # new_x Shape: (batch, 209, 64) -> (batch*209, 64)\n","            # edge_w Shape: (batch, 4112) -> (batch*4112, 1)\n","            # edge_index Shape: (batch, 2, 4112) -> (2, batch*4112)\n","\n","            for i in range(self.gnn_layer):\n","                new_x = self.global_gnn[i](new_x, edge_index, edge_w) # Shape: (batch*209, 32)\n","\n","\n","            \"\"\" Final Forcasting \"\"\"\n","            new_x = self.decoder(new_x, self.w, g_edge_index, g_edge_w, edge_index, edge_w) # Shape: (batch*209, 32)\n","            res = self.predMLP(new_x)\n","            res = res.reshape(-1,self.city_num,self.pred_step) # Shape: (batch, 209, 6)\n","\n","\n","        return res\n","\n","class DecoderModule(nn.Module):\n","    def __init__(self,x_em,edge_h,gnn_h,gnn_layer,city_num,group_num,device):\n","        super(DecoderModule, self).__init__()\n","        self.device = device\n","        self.city_num = city_num\n","        self.group_num = group_num\n","        self.gnn_layer = gnn_layer\n","        self.x_embed = Lin(gnn_h, x_em)\n","        self.group_gnn = nn.ModuleList([NodeModel(x_em,edge_h,gnn_h)])\n","        for i in range(self.gnn_layer-1):\n","            self.group_gnn.append(NodeModel(gnn_h,edge_h,gnn_h))\n","        self.global_gnn = nn.ModuleList([NodeModel(x_em+gnn_h,1,gnn_h)])\n","        for i in range(self.gnn_layer-1):\n","            self.global_gnn.append(NodeModel(gnn_h,1,gnn_h))\n","\n","    def forward(self, x, trans_w, g_edge_index, g_edge_w, edge_index, edge_w):\n","        x = self.x_embed(x)\n","        x = x.reshape(-1,self.city_num,x.shape[-1])\n","\n","        # S\n","        w = Parameter(trans_w,requires_grad=False).to(self.device,non_blocking=True)\n","        w1 = w.transpose(0,1)\n","        w1 = w1.unsqueeze(dim=0)\n","        w1 = w1.repeat_interleave(x.size(0), dim=0)\n","        g_x = torch.bmm(w1, x)\n","        g_x = g_x.reshape(-1, g_x.shape[-1])\n","\n","\n","        for i in range(self.gnn_layer):\n","            g_x = self.group_gnn[i](g_x, g_edge_index, g_edge_w)\n","        g_x = g_x.reshape(-1, self.group_num, g_x.shape[-1])\n","\n","        # S\n","        w2 = w.unsqueeze(dim=0)\n","        w2 = w2.repeat_interleave(g_x.size(0), dim=0)\n","        new_x = torch.bmm(w2,g_x)\n","\n","        # H\n","        new_x = torch.cat([x,new_x],dim=-1)\n","        new_x = new_x.reshape(-1,new_x.shape[-1])\n","\n","        for i in range(self.gnn_layer):\n","            new_x = self.global_gnn[i](new_x,edge_index,edge_w)\n","\n","        return new_x\n","\n","\n","class NodeModel(torch.nn.Module):\n","    def __init__(self,node_h,edge_h,gnn_h):\n","        super(NodeModel, self).__init__()\n","        self.node_mlp_1 = Seq(Lin(node_h+edge_h,gnn_h), ReLU(inplace=False))\n","        self.node_mlp_2 = Seq(Lin(node_h+gnn_h,gnn_h), ReLU(inplace=False))\n","\n","    def forward(self, x, edge_index, edge_attr):\n","        # x: [N, F_x], where N is the number of nodes.\n","        # edge_index: [2, E] with max entry N - 1.\n","        # edge_attr: [E, F_e]\n","        row, col = edge_index\n","        out = torch.cat([x[row], edge_attr], dim=1)\n","        out = self.node_mlp_1(out)\n","        out = scatter_mean(out, col, dim=0, dim_size=x.size(0))\n","        out = torch.cat([x, out], dim=1)\n","        return self.node_mlp_2(out)\n"]},{"cell_type":"markdown","metadata":{"id":"qwyL2a_wOpxB"},"source":["# Dataset"]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import os\n","\n","import torch\n","import torch.utils.data as Data\n","\n","os.chdir('/content/drive/MyDrive/AI_Project/AIP_Project-main')\n","path = './data'\n","\n","class trainDataset(Data.Dataset):\n","\tdef __init__(self, transform=None, train=True):\n","\t\tself.x = np.load(os.path.join(path,'train_x.npy'),allow_pickle=True)\n","\t\tself.u = np.load(os.path.join(path,'train_u.npy'),allow_pickle=True)\n","\t\tself.y = np.load(os.path.join(path,'train_y.npy'),allow_pickle=True)\n","\t\tself.edge_w = np.load(os.path.join(path,'edge_w.npy'),allow_pickle=True)\n","\t\tself.edge_index = np.load(os.path.join(path,'edge_index.npy'),allow_pickle=True)\n","\t\tself.loc = np.load(os.path.join(path,'loc_filled.npy'),allow_pickle=True)\n","\t\tself.loc = self.loc.astype(float)\n","\n","\n","\tdef __getitem__(self, index):\n","\t\tx = torch.FloatTensor(self.x[index]) #(24, 209, 8)\n","\t\tx = x.transpose(0,1) #(209, 24, 8)\n","\t\ty = torch.FloatTensor(self.y[index])\n","\t\ty = y.transpose(0,1)\n","\t\tu = torch.tensor(self.u[index])\n","\t\tedge_index = torch.tensor(self.edge_index)\n","\t\t# edge_index = edge_index.expand((x.size[0],edge_index.size[0],edge_index.size[1]))\n","\t\tedge_w = torch.FloatTensor(self.edge_w)\n","\t\t# edge_w = edge_w.expand((x.size[0],edge_w.size[0]))\n","\t\tloc = torch.FloatTensor(self.loc)\n","\n","\t\treturn [x,u,y,edge_index,edge_w,loc]\n","\n","\tdef __len__(self):\n","\t\treturn self.x.shape[0]\n","\n","class valDataset(Data.Dataset):\n","\tdef __init__(self, transform=None, train=True):\n","\t\tself.x = np.load(os.path.join(path,'val_x.npy'),allow_pickle=True)\n","\t\tself.u = np.load(os.path.join(path,'val_u.npy'),allow_pickle=True)\n","\t\tself.y = np.load(os.path.join(path,'val_y.npy'),allow_pickle=True)\n","\t\tself.edge_w = np.load(os.path.join(path,'edge_w.npy'),allow_pickle=True)\n","\t\tself.edge_index = np.load(os.path.join(path,'edge_index.npy'),allow_pickle=True)\n","\t\tself.loc = np.load(os.path.join(path,'loc_filled.npy'),allow_pickle=True)\n","\t\tself.loc = self.loc.astype(float)\n","\n","\n","\tdef __getitem__(self, index):\n","\t\tx = torch.FloatTensor(self.x[index])\n","\t\tx = x.transpose(0,1)\n","\t\ty = torch.FloatTensor(self.y[index])\n","\t\ty = y.transpose(0,1)\n","\t\tu = torch.tensor(self.u[index])\n","\t\tedge_index = torch.tensor(self.edge_index)\n","\t\t# edge_index = edge_index.expand((x.size[0],edge_index.size[0],edge_index.size[1]))\n","\t\tedge_w = torch.FloatTensor(self.edge_w)\n","\t\t# edge_w = edge_w.expand((x.size[0],edge_w.size[0]))\n","\t\tloc = torch.FloatTensor(self.loc)\n","\n","\t\treturn [x,u,y,edge_index,edge_w,loc]\n","\n","\tdef __len__(self):\n","\t\treturn self.x.shape[0]\n","\n","class testDataset(Data.Dataset):\n","\tdef __init__(self, transform=None, train=True):\n","\t\tself.x = np.load(os.path.join(path,'test_x.npy'),allow_pickle=True)\n","\t\tself.u = np.load(os.path.join(path,'test_u.npy'),allow_pickle=True)\n","\t\tself.y = np.load(os.path.join(path,'test_y.npy'),allow_pickle=True)\n","\t\tself.edge_w = np.load(os.path.join(path,'edge_w.npy'),allow_pickle=True)\n","\t\tself.edge_index = np.load(os.path.join(path,'edge_index.npy'),allow_pickle=True)\n","\t\tself.loc = np.load(os.path.join(path,'loc_filled.npy'),allow_pickle=True)\n","\t\tself.loc = self.loc.astype(float)\n","\n","\n","\tdef __getitem__(self, index):\n","\t\tx = torch.FloatTensor(self.x[index])\n","\t\tx = x.transpose(0,1)\n","\t\ty = torch.FloatTensor(self.y[index])\n","\t\ty = y.transpose(0,1)\n","\t\tu = torch.tensor(self.u[index])\n","\t\tedge_index = torch.tensor(self.edge_index)\n","\t\t# edge_index = edge_index.expand((x.size[0],edge_index.size[0],edge_index.size[1]))\n","\t\tedge_w = torch.FloatTensor(self.edge_w)\n","\t\t# edge_w = edge_w.expand((x.size[0],edge_w.size[0]))\n","\t\tloc = torch.FloatTensor(self.loc)\n","\n","\t\treturn [x,u,y,edge_index,edge_w,loc]\n","\n","\tdef __len__(self):\n","\t\treturn self.x.shape[0]"],"metadata":{"id":"Tb1LwWq48O6k","executionInfo":{"status":"ok","timestamp":1717138325661,"user_tz":-540,"elapsed":326,"user":{"displayName":"백승렬","userId":"14086593896525903207"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["# Set Argument"],"metadata":{"id":"QHmto_V4_IGJ"}},{"cell_type":"code","source":["import torch\n","import numpy as np\n","import shap\n","from torch.utils.data import DataLoader, Subset\n","from sklearn.cluster import KMeans\n","\n","\n","# 설정된 변수\n","device = 'cuda'\n","mode = 'both'\n","encoder = 'self'\n","w_init = 'rand'\n","mark = ''\n","batch_size = 4\n","city_num = 209\n","group_num = 15\n","gnn_h = 32\n","gnn_layer = 2\n","x_em = 32\n","date_em = 4\n","loc_em = 12\n","edge_h = 12\n","pred_step = 1\n","data_usage = 1.0\n","path = './city_air_dataset'"],"metadata":{"id":"Q0nW9KJ_NpDc","executionInfo":{"status":"ok","timestamp":1717138326885,"user_tz":-540,"elapsed":1228,"user":{"displayName":"백승렬","userId":"14086593896525903207"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["# Prepare Model and Data"],"metadata":{"id":"eObdDDLR8aze"}},{"cell_type":"code","source":["# 데이터셋 로드\n","train_dataset = trainDataset()\n","val_dataset = valDataset()\n","test_dataset = testDataset()\n","\n","train_p = list(range(0, int(len(train_dataset) * data_usage)))\n","val_p = list(range(0, int(len(val_dataset) * data_usage)))\n","test_p = list(range(0, int(len(test_dataset) * data_usage)))\n","\n","train_dataset = Subset(train_dataset, train_p)\n","val_dataset = Subset(val_dataset, val_p)\n","test_dataset = Subset(test_dataset, test_p)"],"metadata":{"id":"5jdjKBTLNv5Q","executionInfo":{"status":"ok","timestamp":1717138334675,"user_tz":-540,"elapsed":7797,"user":{"displayName":"백승렬","userId":"14086593896525903207"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n","device = device\n","\n","print(\"Dataload Finished\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"do6fNeOVBE1j","executionInfo":{"status":"ok","timestamp":1717138334677,"user_tz":-540,"elapsed":37,"user":{"displayName":"백승렬","userId":"14086593896525903207"}},"outputId":"2f252b15-bbb7-484d-8ad5-903c5a7861e9"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataload Finished\n"]}]},{"cell_type":"code","source":["\n","# 모델 준비\n","w = None\n","if w_init == 'group':\n","    city_loc = np.load(os.path.join(path, 'loc_filled.npy'), allow_pickle=True)\n","    kmeans = KMeans(n_clusters=group_num, random_state=0).fit(city_loc)\n","    group_list = kmeans.labels_.tolist()\n","    w = np.random.randn(city_num, group_num)\n","    w = w * 0.1\n","    for i in range(len(group_list)):\n","        w[i, group_list[i]] = 1.0\n","    w = torch.FloatTensor(w).to(device, non_blocking=True)\n","\n","city_model = Model(mode, encoder, w_init, w, x_em, date_em, loc_em, edge_h, gnn_h, gnn_layer, city_num, group_num, pred_step, device).to(device)\n","print(\"Model Created\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BX-itfkDG9QK","executionInfo":{"status":"ok","timestamp":1717138335093,"user_tz":-540,"elapsed":447,"user":{"displayName":"백승렬","userId":"14086593896525903207"}},"outputId":"cb4f4aba-d0a7-45ca-9cfc-c52a6a75cbcd"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Model Created\n"]}]},{"cell_type":"markdown","source":["# SHAP"],"metadata":{"id":"mcRu-iU9G_Jc"}},{"cell_type":"code","source":["# 학습된 모델 로드\n","checkpoint = torch.load('self_para_.ckpt')\n","city_model.load_state_dict(checkpoint, strict=False)\n","city_model.eval()\n","\n","# SHAP 분석 준비\n","data_iter = iter(test_loader)\n","sample_data = next(data_iter)  # 첫 번째 배치 사용\n","sample_data = [item.to(device, non_blocking=True) for item in sample_data]\n","x_sample, u_sample, y_sample, edge_index_sample, edge_w_sample, loc_sample = sample_data"],"metadata":{"id":"hoIyeTohFa9q","executionInfo":{"status":"ok","timestamp":1717138336611,"user_tz":-540,"elapsed":1522,"user":{"displayName":"백승렬","userId":"14086593896525903207"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["import gc\n","\n","# 모델 입력 데이터를 float 타입으로 변환\n","inputs = [x_sample, u_sample.float(), edge_index_sample.float(), edge_w_sample, loc_sample]\n","\n","# 모델 내부에서 필요한 부분만 long 타입으로 변환\n","class WrappedModel(nn.Module):\n","    def __init__(self, model):\n","        super(WrappedModel, self).__init__()\n","        self.model = model\n","\n","    def forward(self, x_sample, u_sample, edge_index_sample, edge_w_sample, loc_sample):\n","        return self.model(x_sample, u_sample.long(), edge_index_sample.long(), edge_w_sample, loc_sample)\n","\n","wrapped_model = WrappedModel(city_model)\n","\n","# SHAP explainer 생성\n","explainer = shap.DeepExplainer(wrapped_model, inputs)\n","\n","# 입력 데이터를 작은 배치로 나누기\n","batch_size = 1  # 필요에 따라 조정\n","num_batches = x_sample.shape[0] // batch_size\n","shap_values = []\n","\n","for i in range(num_batches):\n","    print(f\"Processing batch {i + 1}/{num_batches}\")\n","    batch_inputs = [x_sample[i * batch_size:(i + 1) * batch_size],\n","                    u_sample[i * batch_size:(i + 1) * batch_size].float(),\n","                    edge_index_sample[i * batch_size:(i + 1) * batch_size].float(),\n","                    edge_w_sample[i * batch_size:(i + 1) * batch_size],\n","                    loc_sample[i * batch_size:(i + 1) * batch_size]]\n","\n","    batch_shap_values = explainer.shap_values(batch_inputs, check_additivity=False)\n","    shap_values.append(batch_shap_values)\n","\n","    # 메모리 정리\n","    del batch_inputs, batch_shap_values\n","    gc.collect()"],"metadata":{"id":"9zjXUBc19jAZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# SHAP 값 합치기\n","shap_values = [np.concatenate([batch[i] for batch in shap_values], axis=0) for i in range(len(shap_values[0]))]"],"metadata":{"id":"yMyqOMs_ef69","executionInfo":{"status":"ok","timestamp":1717139278956,"user_tz":-540,"elapsed":305,"user":{"displayName":"백승렬","userId":"14086593896525903207"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["for i, shap_value in enumerate(shap_values):\n","    print(f\"shap_value[{i}].shape: {np.array(shap_value).shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NKBWsR_-fZon","executionInfo":{"status":"ok","timestamp":1717139514596,"user_tz":-540,"elapsed":445,"user":{"displayName":"백승렬","userId":"14086593896525903207"}},"outputId":"65eab6eb-0945-4152-eb00-442af21fc85b"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["shap_value[0].shape: (4, 209, 24, 8, 209)\n","shap_value[1].shape: (4, 3, 209)\n","shap_value[2].shape: (4, 2, 4112, 209)\n","shap_value[3].shape: (4, 4112, 209)\n","shap_value[4].shape: (4, 209, 2, 209)\n"]}]},{"cell_type":"code","source":["# 개별 샘플에 대한 Waterfall 플롯 그리기\n","sample_index = 0  # 시각화할 샘플 인덱스\n","shap_values_np = np.array(shap_values)\n","\n","# SHAP 값 시각화\n","shap.plots.waterfall(shap.Explanation(values=shap_values_np[sample_index],\n","                                      base_values=explainer.expected_value[sample_index],\n","                                      data=inputs[0][sample_index].cpu().numpy()))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":219},"id":"pj7FnyQgYx2B","executionInfo":{"status":"error","timestamp":1717140080570,"user_tz":-540,"elapsed":429,"user":{"displayName":"백승렬","userId":"14086593896525903207"}},"outputId":"63167c51-5029-476a-f0a8-f93e2b58864f"},"execution_count":15,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'shap_values_combined' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-ffe33fbff452>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Waterfall 플롯을 그리기 위해 필요한 샘플 선택\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msample_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m  \u001b[0;31m# 시각화할 샘플 인덱스\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mshap_values_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshap_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mshap_value\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mshap_values_combined\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# 필요한 데이터를 선택하여 플롯 생성\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'shap_values_combined' is not defined"]}]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"collapsed_sections":["4nrZ0wvYOwnu","TPwHsMvyOn7N","qwyL2a_wOpxB","eObdDDLR8aze"],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}