{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1ITH_00Q1nQ57eN-E0JyXR3Ashexl6wF0","authorship_tag":"ABX9TyM0Job9qOerArOZNpV90Um6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import torch\n","print(torch.__version__)\n","print(torch.version.cuda)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1ZuQE0bqgQsk","executionInfo":{"status":"ok","timestamp":1716268404043,"user_tz":-540,"elapsed":8107,"user":{"displayName":"PKyil","userId":"08420955355994381528"}},"outputId":"49d7218d-5dfa-4240-dcbf-cb257b58cbe3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2.2.1+cu121\n","12.1\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kd-0aOPwf5gc","executionInfo":{"status":"ok","timestamp":1716268420314,"user_tz":-540,"elapsed":7422,"user":{"displayName":"PKyil","userId":"08420955355994381528"}},"outputId":"7d5d9186-6c7c-4574-af73-8db4be89d13c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in links: https://pytorch-geometric.com/whl/torch-2.2.1+cu121.html\n","Collecting torch-scatter==2.1.2\n","  Downloading https://data.pyg.org/whl/torch-2.2.0%2Bcu121/torch_scatter-2.1.2%2Bpt22cu121-cp310-cp310-linux_x86_64.whl (10.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m65.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: torch-scatter\n","Successfully installed torch-scatter-2.1.2+pt22cu121\n"]}],"source":["!pip install torch-scatter==2.1.2 -f https://pytorch-geometric.com/whl/torch-2.2.1+cu121.html"]},{"cell_type":"code","source":["!pip install torch-geometric"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ScSneTSlgNrx","executionInfo":{"status":"ok","timestamp":1716268439027,"user_tz":-540,"elapsed":13885,"user":{"displayName":"PKyil","userId":"08420955355994381528"}},"outputId":"cdcfd2d1-98ce-4b82-92bf-ee8e5c4757ec"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torch-geometric\n","  Downloading torch_geometric-2.5.3-py3-none-any.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.25.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.11.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2023.6.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.9.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.2.2)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.5.0)\n","Installing collected packages: torch-geometric\n","Successfully installed torch-geometric-2.5.3\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4l0GL00bjRgR","executionInfo":{"status":"ok","timestamp":1716268190907,"user_tz":-540,"elapsed":8624,"user":{"displayName":"PKyil","userId":"08420955355994381528"}},"outputId":"170a87fc-7134-48bd-f1b0-f81a6ea1a26c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["### Model"],"metadata":{"id":"sH5xQg_AgXuR"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from torch.nn import Sequential as Seq, Linear as Lin, ReLU\n","from torch.nn import TransformerEncoderLayer, TransformerEncoder\n","from torch.nn.parameter import Parameter\n","from torch_scatter import scatter_mean\n","from torch_geometric.nn import MetaLayer\n","\n","TIME_WINDOW = 24\n","PRED_LEN = 6\n"],"metadata":{"id":"s9LSoJpfhUuE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Model(nn.Module):\n","\tdef __init__(self,mode,encoder,w_init,w,x_em,date_em,loc_em,edge_h,gnn_h,gnn_layer,city_num,group_num,pred_step,device):\n","\t\tsuper(Model, self).__init__()\n","\t\tself.device = device\n","\t\tself.mode = mode\n","\t\tself.encoder = encoder\n","\t\tself.w_init = w_init\n","\t\tself.city_num = city_num\n","\t\tself.group_num = group_num\n","\t\tself.edge_h = edge_h\n","\t\tself.gnn_layer = gnn_layer\n","\t\tself.pred_step = pred_step\n","\n","\t\tif self.encoder == 'self':\n","\t\t\tself.encoder_layer = TransformerEncoderLayer(8, nhead=4, dim_feedforward=256) ### to extract the features ( self attention , 특정시점의 도시의 8개의 특성끼리 attention )\n","\t\t\t# self.x_embed = Lin(8, x_em)\n","\t\t\tself.x_embed = Lin(TIME_WINDOW*8, x_em) ### to obtain city representation\n","\n","\t\telif self.encoder == 'lstm':\n","\t\t\tself.input_LSTM = nn.LSTM(8,x_em,num_layers=1,batch_first=True)\n","\t\tif self.w_init == 'rand':\n","\t\t\tself.w = Parameter(torch.randn(city_num,group_num).to(device,non_blocking=True),requires_grad=True)\n","\t\telif self.w_init == 'group':\n","\t\t\tself.w = Parameter(w,requires_grad=True)\n","\t\tself.loc_embed = Lin(2, loc_em)\n","\t\tself.u_embed1 = nn.Embedding(12, date_em) #month\n","\t\tself.u_embed2 = nn.Embedding(7, date_em) #week\n","\t\tself.u_embed3 = nn.Embedding(24, date_em) #hour\n","\t\tself.edge_inf = Seq(Lin(x_em*2+date_em*3+loc_em*2,edge_h),ReLU(inplace=True))\n","\t\tself.group_gnn = nn.ModuleList([NodeModel(x_em+loc_em,edge_h,gnn_h)])\n","\t\tfor i in range(self.gnn_layer-1):\n","\t\t\tself.group_gnn.append(NodeModel(gnn_h,edge_h,gnn_h))\n","\t\tself.global_gnn = nn.ModuleList([NodeModel(x_em+gnn_h,1,gnn_h)])\n","\t\tfor i in range(self.gnn_layer-1):\n","\t\t\tself.global_gnn.append(NodeModel(gnn_h,1,gnn_h))\n","\t\tif self.mode == 'ag':\n","\t\t\tself.decoder = DecoderModule(x_em,edge_h,gnn_h,gnn_layer,city_num,group_num,device)\n","\t\t\tself.predMLP = Seq(Lin(gnn_h,16),ReLU(inplace=True),Lin(16,1),ReLU(inplace=True))\n","\t\tif self.mode == 'full':\n","\t\t\tself.decoder = DecoderModule(x_em,edge_h,gnn_h,gnn_layer,city_num,group_num,device)\n","\t\t\tself.predMLP = Seq(Lin(gnn_h,16),ReLU(inplace=True),Lin(16,self.pred_step),ReLU(inplace=True))\n","\t\tself.TemporalAggregateMLP = Seq(Lin(gnn_h+8,gnn_h),ReLU(inplace=True))\n","\n","\tdef batchInput(self,x,edge_w,edge_index):\n","\t\tsta_num = x.shape[1]\n","\t\tx = x.reshape(-1,x.shape[-1])\n","\t\tedge_w = edge_w.reshape(-1,edge_w.shape[-1])\n","\t\tfor i in range(edge_index.size(0)):\n","\t\t\tedge_index[i,:] = torch.add(edge_index[i,:], i*sta_num)\n","\t\t# print(edge_index.shape)\n","\t\tedge_index = edge_index.transpose(0,1)\n","\t\t# print(edge_index.shape)\n","\t\tedge_index = edge_index.reshape(2,-1)\n","\t\treturn x, edge_w, edge_index\n","\n","\tdef forward(self,x,u,edge_index,edge_w,loc):\n","\t\tx = x.reshape(-1,x.shape[2],x.shape[3])\n","\t\tif self.encoder == 'self':\n","\t\t\t# [S,B,E]\n","\t\t\t# print(x.shape)\n","\t\t\tx = x.transpose(0,1)\n","\t\t\tx = self.encoder_layer(x)\n","\t\t\tx = x.transpose(0,1)\n","\t\t\tx2 = x.reshape(-1,self.city_num,x.shape[1],x.shape[2])  ## (batch size, num of city, 24h, 8features )\n","\t\t\t# print(x.shape)\n","\t\t\tx = x.reshape(-1,self.city_num,TIME_WINDOW*x.shape[-1])\n","\t\t\tx = self.x_embed(x)\n","\t\t\t# x = x.reshape(-1,self.city_num,TIME_WINDOW,x.shape[-1])\n","\t\t\t# x = torch.max(x,dim=-2).values\n","\t\t\t# print(x.shape)\n","\t\telif self.encoder == 'lstm':\n","\t\t\t_,(x,_) = self.input_LSTM(x)\n","\t\t\tx = x.reshape(-1,self.city_num,x.shape[-1])\n","\t\t\t# print(x.shape)\n","\n","\t\tx2 = torch.index_select(x2, dim=2, index=torch.tensor([3, 7, 11, 15, 19, 23]).to('cuda')) ## ( batch size, num of city, selected 6h, 8features )\n","\t\tx2 = x2.transpose(1,2) ## ( batch size, selected 6h , num of city, 8features ) [batch size, 6, 209, 8]\n","\n","\t\th_other5 = x2[:, :-1, :, :]  # [batch size, 5, 209, 8]\n","\t\th_other5 = h_other5.reshape(-1,h_other5.shape[1]*h_other5.shape[2],h_other5.shape[3])  # [batch size, 1045, 8]\n","\n","\t\th24 = x2[:, -1:, :, :]  # [batch size, 1, 209, 8]\n","\t\th24 = h24.reshape(-1,h24.shape[2],h24.shape[3]) # [batch size, 209, 8]\n","\t\th24 = h24.transpose(1,2)\n","\n","\t\tattention_scores = torch.matmul(h_other5, h24)   # [batch size, 1045, 209]\n","\t\tattention_scores = attention_scores.reshape(-1,5,209,attention_scores.shape[2])  # [batch size, 5, 209, 209]\n","\t\tattention_weights = F.softmax(attention_scores, dim=1)  # [batch size, 5, 209, 209]\n","\n","\t\th_other5 = h_other5.reshape(-1,5,209,h_other5.shape[2]) # [batch size, 5, 209, 8]\n","\t\th_other5 = h_other5.transpose(2,3) # [batch size, 5, 8, 209]\n","\n","\t\tattention_weighted_sum = torch.matmul(h_other5, attention_weights) # [batch size, 5, 8, 209]\n","\t\tattention_weighted_sum = attention_weighted_sum.transpose(2,3)\n","\t\tx2 = torch.sum(attention_weighted_sum, dim=1)  # [batch size, 209, 8]\n","\n","\n","\t\t# graph pooling\n","\t\t# print(self.w[10])\n","\t\tw = F.softmax(self.w)\n","\t\tw1 = w.transpose(0,1)\n","\t\tw1 = w1.unsqueeze(dim=0)\n","\t\tw1 = w1.repeat_interleave(x.size(0), dim=0)\n","\t\t# print(w.shape,x.shape)\n","\t\t# print(loc.shape)\n","\t\tloc = self.loc_embed(loc)\n","\t\tx_loc = torch.cat([x,loc],dim=-1)\n","\t\tg_x = torch.bmm(w1,x_loc)\n","\t\t# print(g_x.shape)\n","\n","\t\t# group gnn\n","\t\tu_em1 = self.u_embed1(u[:,0])\n","\t\tu_em2 = self.u_embed2(u[:,1])\n","\t\tu_em3 = self.u_embed3(u[:,2])\n","\t\tu_em = torch.cat([u_em1,u_em2,u_em3],dim=-1)\n","\t\t# print(u_em.shape)\n","\t\tfor i in range(self.group_num):\n","\t\t\tfor j in range(self.group_num):\n","\t\t\t\tif i == j: continue\n","\t\t\t\tg_edge_input = torch.cat([g_x[:,i],g_x[:,j],u_em],dim=-1)\n","\t\t\t\ttmp_g_edge_w = self.edge_inf(g_edge_input)\n","\t\t\t\ttmp_g_edge_w = tmp_g_edge_w.unsqueeze(dim=0)\n","\t\t\t\ttmp_g_edge_index = torch.tensor([i,j]).unsqueeze(dim=0).to(self.device,non_blocking=True)\n","\t\t\t\tif i == 0 and j == 1:\n","\t\t\t\t\tg_edge_w = tmp_g_edge_w\n","\t\t\t\t\tg_edge_index = tmp_g_edge_index\n","\t\t\t\telse:\n","\t\t\t\t\tg_edge_w = torch.cat([g_edge_w,tmp_g_edge_w],dim=0)\n","\t\t\t\t\tg_edge_index = torch.cat([g_edge_index,tmp_g_edge_index],dim=0)\n","\t\t# print(g_edge_w.shape,g_edge_index.shape)\n","\t\tg_edge_w = g_edge_w.transpose(0,1)\n","\t\tg_edge_index = g_edge_index.unsqueeze(dim=0)\n","\t\tg_edge_index = g_edge_index.repeat_interleave(u_em.shape[0],dim=0)\n","\t\tg_edge_index = g_edge_index.transpose(1,2)\n","\t\t# print(g_x.shape,g_edge_w.shape,g_edge_index.shape)\n","\t\tg_x, g_edge_w, g_edge_index = self.batchInput(g_x, g_edge_w, g_edge_index)\n","\t\t# print(g_x.shape,g_edge_w.shape,g_edge_index.shape)\n","\t\tfor i in range(self.gnn_layer):\n","\t\t\tg_x = self.group_gnn[i](g_x,g_edge_index,g_edge_w)\n","\n","\t\tg_x = g_x.reshape(-1,self.group_num,g_x.shape[-1])\n","\t\t# print(g_x.shape,self.w.shape)\n","\t\tw2 = w.unsqueeze(dim=0)\n","\t\tw2 = w2.repeat_interleave(g_x.size(0), dim=0)\n","\t\tnew_x = torch.bmm(w2,g_x)\n","\t\t# print(new_x.shape,x.shape)\n","\t\tnew_x = torch.cat([x,new_x],dim=-1)\n","\t\tedge_w = edge_w.unsqueeze(dim=-1)\n","\t\t# print(new_x.shape,edge_w.shape,edge_index.shape)\n","\t\tnew_x, edge_w, edge_index = self.batchInput(new_x, edge_w, edge_index)\n","\t\t# print(new_x.shape,edge_w.shape,edge_index.shape)\n","\t\tfor i in range(self.gnn_layer):\n","\t\t\tnew_x = self.global_gnn[i](new_x,edge_index,edge_w)\n","\t\t# print(new_x.shape)\n","\n","\t\tx2 = x2.reshape(-1,x2.shape[-1])\n","\t\tnew_x = torch.cat([x2,new_x],dim=-1)\n","\t\tnew_x = self.TemporalAggregateMLP(new_x)\n","\n","\t\tif self.mode == 'ag':\n","\t\t\tfor i in range(self.pred_step):\n","\t\t\t\tnew_x = self.decoder(new_x,self.w,g_edge_index,g_edge_w,edge_index,edge_w)\n","\t\t\t\ttmp_res = self.predMLP(new_x)\n","\t\t\t\ttmp_res = tmp_res.reshape(-1,self.city_num)\n","\t\t\t\ttmp_res = tmp_res.unsqueeze(dim=-1)\n","\t\t\t\tif i == 0:\n","\t\t\t\t\tres = tmp_res\n","\t\t\t\telse:\n","\t\t\t\t\tres = torch.cat([res,tmp_res],dim=-1)\n","\t\tif self.mode == 'full':\n","\t\t\tnew_x = self.decoder(new_x,self.w,g_edge_index,g_edge_w,edge_index,edge_w)\n","\t\t\tres = self.predMLP(new_x)\n","\t\t\tres = res.reshape(-1,self.city_num,self.pred_step)\n","\n","\t\t# print(res.shape)\n","\t\treturn res\n","\n","class DecoderModule(nn.Module):\n","\tdef __init__(self,x_em,edge_h,gnn_h,gnn_layer,city_num,group_num,device):\n","\t\tsuper(DecoderModule, self).__init__()\n","\t\tself.device = device\n","\t\tself.city_num = city_num\n","\t\tself.group_num = group_num\n","\t\tself.gnn_layer = gnn_layer\n","\t\tself.x_embed = Lin(gnn_h, x_em)\n","\t\tself.group_gnn = nn.ModuleList([NodeModel(x_em,edge_h,gnn_h)])\n","\t\tfor i in range(self.gnn_layer-1):\n","\t\t\tself.group_gnn.append(NodeModel(gnn_h,edge_h,gnn_h))\n","\t\tself.global_gnn = nn.ModuleList([NodeModel(x_em+gnn_h,1,gnn_h)])\n","\t\tfor i in range(self.gnn_layer-1):\n","\t\t\tself.global_gnn.append(NodeModel(gnn_h,1,gnn_h))\n","\n","\tdef forward(self,x,trans_w,g_edge_index,g_edge_w,edge_index,edge_w):\n","\t\tx = self.x_embed(x)\n","\t\tx = x.reshape(-1,self.city_num,x.shape[-1])\n","\t\tw = Parameter(trans_w,requires_grad=False).to(self.device,non_blocking=True)\n","\t\tw1 = w.transpose(0,1)\n","\t\tw1 = w1.unsqueeze(dim=0)\n","\t\tw1 = w1.repeat_interleave(x.size(0), dim=0)\n","\t\tg_x = torch.bmm(w1,x)\n","\t\tg_x = g_x.reshape(-1,g_x.shape[-1])\n","\t\tfor i in range(self.gnn_layer):\n","\t\t\tg_x = self.group_gnn[i](g_x,g_edge_index,g_edge_w)\n","\t\tg_x = g_x.reshape(-1,self.group_num,g_x.shape[-1])\n","\t\tw2 = w.unsqueeze(dim=0)\n","\t\tw2 = w2.repeat_interleave(g_x.size(0), dim=0)\n","\t\tnew_x = torch.bmm(w2,g_x)\n","\t\tnew_x = torch.cat([x,new_x],dim=-1)\n","\t\tnew_x = new_x.reshape(-1,new_x.shape[-1])\n","\t\t# print(new_x.shape,edge_w.shape,edge_index.shape)\n","\t\tfor i in range(self.gnn_layer):\n","\t\t\tnew_x = self.global_gnn[i](new_x,edge_index,edge_w)\n","\n","\t\treturn new_x\n","\n","\n","class NodeModel(torch.nn.Module):\n","    def __init__(self,node_h,edge_h,gnn_h):\n","        super(NodeModel, self).__init__()\n","        self.node_mlp_1 = Seq(Lin(node_h+edge_h,gnn_h), ReLU(inplace=True))\n","        self.node_mlp_2 = Seq(Lin(node_h+gnn_h,gnn_h), ReLU(inplace=True))\n","\n","    def forward(self, x, edge_index, edge_attr):\n","        # x: [N, F_x], where N is the number of nodes.\n","        # edge_index: [2, E] with max entry N - 1.\n","        # edge_attr: [E, F_e]\n","        row, col = edge_index\n","        out = torch.cat([x[row], edge_attr], dim=1)\n","        out = self.node_mlp_1(out)\n","        out = scatter_mean(out, col, dim=0, dim_size=x.size(0))\n","        out = torch.cat([x, out], dim=1)\n","        return self.node_mlp_2(out)"],"metadata":{"id":"64FpJHR4hb6L"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Dataset"],"metadata":{"id":"S5v4ZZ2ihszK"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import os\n","\n","import torch\n","import torch.utils.data as Data\n","\n","\n","path = '/content/drive/MyDrive/SKKU_AI_proj/project/GAGNN/GAGNN/data' ## set dataset path"],"metadata":{"id":"EasGmcQYh_CC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class trainDataset(Data.Dataset):\n","\tdef __init__(self, transform=None, train=True):\n","\t\tself.x = np.load(os.path.join(path,'train_x.npy'),allow_pickle=True)\n","\t\tself.u = np.load(os.path.join(path,'train_u.npy'),allow_pickle=True)\n","\t\tself.y = np.load(os.path.join(path,'train_y.npy'),allow_pickle=True)\n","\t\tself.edge_w = np.load(os.path.join(path,'edge_w.npy'),allow_pickle=True)\n","\t\tself.edge_index = np.load(os.path.join(path,'edge_index.npy'),allow_pickle=True)\n","\t\tself.loc = np.load(os.path.join(path,'loc_filled.npy'),allow_pickle=True)\n","\t\tself.loc = self.loc.astype(np.float64)\n","\n","\n","\tdef __getitem__(self, index):\n","\t\tx = torch.FloatTensor(self.x[index])\n","\t\tx = x.transpose(0,1)\n","\t\ty = torch.FloatTensor(self.y[index])\n","\t\ty = y.transpose(0,1)\n","\t\tu = torch.tensor(self.u[index])\n","\t\tedge_index = torch.tensor(self.edge_index)\n","\t\t# edge_index = edge_index.expand((x.size[0],edge_index.size[0],edge_index.size[1]))\n","\t\tedge_w = torch.FloatTensor(self.edge_w)\n","\t\t# edge_w = edge_w.expand((x.size[0],edge_w.size[0]))\n","\t\tloc = torch.FloatTensor(self.loc)\n","\n","\t\treturn [x,u,y,edge_index,edge_w,loc]\n","\n","\tdef __len__(self):\n","\t\treturn self.x.shape[0]\n","\n","class valDataset(Data.Dataset):\n","\tdef __init__(self, transform=None, train=True):\n","\t\tself.x = np.load(os.path.join(path,'val_x.npy'),allow_pickle=True)\n","\t\tself.u = np.load(os.path.join(path,'val_u.npy'),allow_pickle=True)\n","\t\tself.y = np.load(os.path.join(path,'val_y.npy'),allow_pickle=True)\n","\t\tself.edge_w = np.load(os.path.join(path,'edge_w.npy'),allow_pickle=True)\n","\t\tself.edge_index = np.load(os.path.join(path,'edge_index.npy'),allow_pickle=True)\n","\t\tself.loc = np.load(os.path.join(path,'loc_filled.npy'),allow_pickle=True)\n","\t\tself.loc = self.loc.astype(np.float64)\n","\n","\n","\tdef __getitem__(self, index):\n","\t\tx = torch.FloatTensor(self.x[index])\n","\t\tx = x.transpose(0,1)\n","\t\ty = torch.FloatTensor(self.y[index])\n","\t\ty = y.transpose(0,1)\n","\t\tu = torch.tensor(self.u[index])\n","\t\tedge_index = torch.tensor(self.edge_index)\n","\t\t# edge_index = edge_index.expand((x.size[0],edge_index.size[0],edge_index.size[1]))\n","\t\tedge_w = torch.FloatTensor(self.edge_w)\n","\t\t# edge_w = edge_w.expand((x.size[0],edge_w.size[0]))\n","\t\tloc = torch.FloatTensor(self.loc)\n","\n","\t\treturn [x,u,y,edge_index,edge_w,loc]\n","\n","\tdef __len__(self):\n","\t\treturn self.x.shape[0]\n","\n","class testDataset(Data.Dataset):\n","\tdef __init__(self, transform=None, train=True):\n","\t\tself.x = np.load(os.path.join(path,'test_x.npy'),allow_pickle=True)\n","\t\tself.u = np.load(os.path.join(path,'test_u.npy'),allow_pickle=True)\n","\t\tself.y = np.load(os.path.join(path,'test_y.npy'),allow_pickle=True)\n","\t\tself.edge_w = np.load(os.path.join(path,'edge_w.npy'),allow_pickle=True)\n","\t\tself.edge_index = np.load(os.path.join(path,'edge_index.npy'),allow_pickle=True)\n","\t\tself.loc = np.load(os.path.join(path,'loc_filled.npy'),allow_pickle=True)\n","\t\tself.loc = self.loc.astype(np.float64)\n","\n","\n","\tdef __getitem__(self, index):\n","\t\tx = torch.FloatTensor(self.x[index])\n","\t\tx = x.transpose(0,1)\n","\t\ty = torch.FloatTensor(self.y[index])\n","\t\ty = y.transpose(0,1)\n","\t\tu = torch.tensor(self.u[index])\n","\t\tedge_index = torch.tensor(self.edge_index)\n","\t\t# edge_index = edge_index.expand((x.size[0],edge_index.size[0],edge_index.size[1]))\n","\t\tedge_w = torch.FloatTensor(self.edge_w)\n","\t\t# edge_w = edge_w.expand((x.size[0],edge_w.size[0]))\n","\t\tloc = torch.FloatTensor(self.loc)\n","\n","\t\treturn [x,u,y,edge_index,edge_w,loc]\n","\n","\tdef __len__(self):\n","\t\treturn self.x.shape[0]"],"metadata":{"id":"0ySMDvB8h07x"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Train"],"metadata":{"id":"zDpWDzXaibKJ"}},{"cell_type":"code","source":["import time\n","import os\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.utils.data as Data\n","from sklearn.cluster import KMeans\n","from torch_geometric.nn import MetaLayer\n","\n","import argparse"],"metadata":{"id":"b-jAK1xjia32"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Args:\n","    device = 'cuda'\n","    mode = 'full'\n","    encoder = 'self'\n","    w_init = 'rand'\n","    mark = ''\n","    run_times = 1\n","    epoch = 1\n","    batch_size = 64\n","    w_rate = 50\n","    city_num = 209\n","    group_num = 15\n","    gnn_h = 32\n","    gnn_layer = 2\n","    x_em = 32\n","    date_em = 4\n","    loc_em = 12\n","    edge_h = 12\n","    lr = 0.001\n","    wd = 0.001\n","    pred_step = 6\n","\n","args = Args()\n","print(args.device, args.mode, args.encoder, args.w_init, args.mark, args.run_times, args.epoch, args.batch_size, args.w_rate, args.city_num, args.group_num, args.gnn_h, args.gnn_layer, args.x_em, args.date_em, args.loc_em, args.edge_h, args.lr, args.wd, args.pred_step)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iOrATV5Qijt-","executionInfo":{"status":"ok","timestamp":1716268474031,"user_tz":-540,"elapsed":5,"user":{"displayName":"PKyil","userId":"08420955355994381528"}},"outputId":"d831cf6a-0d96-4f57-ddeb-5520fd87558d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda full self rand  1 1 64 50 209 15 32 2 32 4 12 12 0.001 0.001 6\n"]}]},{"cell_type":"code","source":["train_dataset = trainDataset()\n","val_dataset = valDataset()\n","test_dataset = testDataset()\n","print(len(train_dataset)+len(val_dataset)+len(test_dataset))\n","train_loader = Data.DataLoader(train_dataset, batch_size=args.batch_size,\n","    shuffle=True, num_workers=8, pin_memory=True)\n","val_loader = Data.DataLoader(val_dataset, batch_size=args.batch_size,\n","    shuffle=False, num_workers=8, pin_memory=True)\n","test_loader = Data.DataLoader(test_dataset, batch_size=args.batch_size,\n","    shuffle=False, num_workers=8, pin_memory=True)\n","\n","device = args.device\n","# city_index = [0,2,30,32,43]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2lh2MwWCim7s","executionInfo":{"status":"ok","timestamp":1716268581940,"user_tz":-540,"elapsed":105348,"user":{"displayName":"PKyil","userId":"08420955355994381528"}},"outputId":"a24dca47-840e-40be-e3bf-c33fc4467931"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["20370\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]}]},{"cell_type":"code","source":["for _ in range(args.run_times):\n","\tstart = time.time()\n","\n","\tw = None\n","\tif args.w_init == 'group':\n","\t\tcity_loc = np.load(os.path.join(path,'loc_filled.npy'),allow_pickle=True)\n","\t\tkmeans = KMeans(n_clusters=args.group_num, random_state=0).fit(city_loc)\n","\t\tgroup_list = kmeans.labels_.tolist()\n","\t\tw = np.random.randn(args.city_num,args.group_num)\n","\t\tw = w * 0.1\n","\t\tfor i in range(len(group_list)):\n","\t\t\tw[i,group_list[i]] = 1.0\n","\t\tw = torch.FloatTensor(w).to(device,non_blocking=True)\n","\n","\tcity_model = Model(args.mode,args.encoder,args.w_init,w,args.x_em,args.date_em,args.loc_em,args.edge_h,args.gnn_h,\n","\t\t\targs.gnn_layer,args.city_num,args.group_num,args.pred_step,device).to(device)\n","\tcity_num = sum(p.numel() for p in city_model.parameters() if p.requires_grad)\n","\tprint('city_model:', 'Trainable,', city_num)\n","\t# print(city_model)\n","\tcriterion = nn.L1Loss(reduction = 'sum')\n","\tall_params = city_model.parameters()\n","\tw_params = []\n","\tother_params = []\n","\tfor pname, p in city_model.named_parameters():\n","\t\tif pname == 'w':\n","\t\t\tw_params += [p]\n","\tparams_id = list(map(id, w_params))\n","\tother_params = list(filter(lambda p: id(p) not in params_id, all_params))\n","\t# print(len(w_params),len(other_params))\n","\toptimizer = torch.optim.Adam([\n","        {'params': other_params},\n","        {'params': w_params, 'lr': args.lr * args.w_rate}\n","    ], lr=args.lr, weight_decay=args.wd)\n","\n","\tval_loss_min = np.inf\n","\tfor epoch in range(args.epoch):\n","\t\tfor i,data in enumerate(train_loader):\n","\t\t\tdata = [item.to(device,non_blocking=True) for item in data]\n","\t\t\tx,u,y,edge_index,edge_w,loc = data\n","\t\t\toutputs = city_model(x,u,edge_index,edge_w,loc)\n","\t\t\tloss = criterion(y,outputs)\n","\t\t\tcity_model.zero_grad()\n","\t\t\tloss.backward()\n","\t\t\toptimizer.step()\n","\n","\t\t\tif epoch % 10 == 0 and i % 100 == 0:\n","\t\t\t\tprint('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n","\t\t\t\t\t\t.format(epoch, args.epoch, i, int(len(train_dataset)/args.batch_size), loss.item()))\n","\n","\t\tif epoch % 5 == 0:\n","\t\t\twith torch.no_grad():\n","\t\t\t\tval_loss = 0\n","\t\t\t\tfor j, data_val in enumerate(val_loader):\n","\t\t\t\t\tdata_val = [item.to(device,non_blocking=True) for item in data_val]\n","\t\t\t\t\tx_val,u_val,y_val,edge_index_val,edge_w_val,loc_val = data_val\n","\t\t\t\t\toutputs_val = city_model(x_val,u_val,edge_index_val,edge_w_val,loc_val)\n","\t\t\t\t\tbatch_loss = criterion(y_val,outputs_val)\n","\t\t\t\t\tval_loss += batch_loss.item()\n","\t\t\t\tprint('Epoch:',epoch,', val_loss:',val_loss)\n","\t\t\t\tif val_loss < val_loss_min:\n","\t\t\t\t\ttorch.save(city_model.state_dict(),args.encoder+'_para_'+args.mark+'.ckpt')\n","\t\t\t\t\tval_loss_min = val_loss\n","\t\t\t\t\tprint('parameters have been updated during epoch ',epoch)\n","\n","\tmae_loss = torch.zeros(args.city_num,args.pred_step).to(device)\n","\trmse_loss = torch.zeros(args.city_num,args.pred_step).to(device)\n","\n","\tdef cal_loss(outputs,y):\n","\t\tglobal mae_loss, rmse_loss\n","\t\ttemp_loss = torch.abs(outputs-y)\n","\t\tmae_loss = torch.add(mae_loss,temp_loss.sum(dim=0))\n","\n","\t\ttemp_loss = torch.pow(temp_loss,2)\n","\t\trmse_loss = torch.add(rmse_loss,temp_loss.sum(dim=0))\n","\n","\n","\twith torch.no_grad():\n","\t\tcity_model.load_state_dict(torch.load(args.encoder+'_para_'+args.mark+'.ckpt'))\n","\t\tw_weight = city_model.state_dict()['w']\n","\t\tw_weight = F.softmax(w_weight)\n","\t\t_,w_weight = torch.max(w_weight,dim=-1)\n","\t\tprint(w_weight.cpu().tolist())\n","\n","\t\tfor i, data in enumerate(test_loader):\n","\t\t\tdata = [item.to(device,non_blocking=True) for item in data]\n","\t\t\tx,u,y,edge_index,edge_w,loc = data\n","\t\t\toutputs = city_model(x,u,edge_index,edge_w,loc)\n","\t\t\tcal_loss(outputs,y)\n","\n","\t\tmae_loss = mae_loss/(len(test_dataset))\n","\t\trmse_loss = rmse_loss/(len(test_dataset))\n","\t\tmae_loss = mae_loss.mean(dim=0)\n","\t\trmse_loss = rmse_loss.mean(dim=0)\n","\n","\t\tend = time.time()\n","\t\tprint('Running time: %s Seconds'%(end-start))\n","\n","\t\tmae_loss = mae_loss.cpu()\n","\t\trmse_loss = rmse_loss.cpu()\n","\n","\t\tprint('mae:', np.array(mae_loss))\n","\t\tprint('rmse:', np.sqrt(np.array(rmse_loss)))\n","\n","\t\t# for i, data in enumerate(Data.DataLoader(test_dataset, batch_size=1,shuffle=False, pin_memory=True)):\n","\t\t# \tdata = [item.to(device,non_blocking=True) for item in data]\n","\t\t# \tx,u,y,edge_index,edge_w,loc = data\n","\t\t# \toutputs = city_model(x,u,edge_index,edge_w,loc)\n","\t\t# \tif i == 305:\n","\t\t# \t\tprint(x[:,0])\n","\t\t# \t\tprint(outputs[:,0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Il2IjO3gipFa","executionInfo":{"status":"ok","timestamp":1716268656959,"user_tz":-540,"elapsed":69764,"user":{"displayName":"PKyil","userId":"08420955355994381528"}},"outputId":"dd69cf84-69a3-4c8f-b439-03bb2e93ce7a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["city_model: Trainable, 50025\n"]},{"output_type":"stream","name":"stderr","text":["/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","<ipython-input-7-e8ca64cf9163>:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  w = F.softmax(self.w)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [0/1], Step [0/222], Loss: 5474274.0000\n","Epoch [0/1], Step [100/222], Loss: 2601227.0000\n","Epoch [0/1], Step [200/222], Loss: 2475348.2500\n"]},{"output_type":"stream","name":"stderr","text":["/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 0 , val_loss: 55513414.75\n","parameters have been updated during epoch  0\n","[3, 13, 1, 13, 14, 7, 13, 13, 13, 2, 8, 3, 5, 7, 13, 13, 8, 13, 13, 11, 3, 2, 11, 7, 13, 11, 3, 9, 5, 5, 4, 13, 12, 11, 11, 13, 3, 1, 9, 11, 13, 4, 8, 13, 3, 13, 13, 8, 3, 13, 7, 13, 11, 3, 13, 9, 11, 11, 9, 7, 3, 3, 13, 11, 1, 11, 12, 5, 11, 1, 3, 11, 3, 11, 9, 8, 11, 3, 8, 3, 13, 8, 13, 11, 8, 13, 11, 3, 7, 11, 1, 2, 11, 13, 8, 8, 13, 11, 3, 11, 1, 1, 5, 12, 8, 14, 13, 8, 7, 7, 13, 9, 13, 8, 13, 9, 3, 3, 9, 3, 8, 6, 8, 10, 13, 12, 3, 13, 12, 3, 8, 14, 13, 9, 9, 8, 8, 13, 7, 8, 14, 8, 3, 13, 11, 3, 13, 7, 1, 11, 2, 7, 14, 8, 3, 11, 13, 11, 11, 11, 3, 1, 7, 1, 3, 3, 13, 13, 3, 13, 11, 7, 14, 12, 9, 8, 8, 5, 8, 11, 5, 11, 3, 3, 11, 6, 9, 7, 4, 12, 12, 2, 8, 8, 13, 8, 8, 13, 4, 7, 11, 11, 11, 11, 13, 8, 13, 6, 3]\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-13-0f1babfe465e>:80: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  w_weight = F.softmax(w_weight)\n"]},{"output_type":"stream","name":"stdout","text":["Running time: 69.3779878616333 Seconds\n","mae: [73.84241  29.602959 29.521553 29.625525 29.709352 29.756117]\n","rmse: [91.26294  45.754723 45.77058  45.881382 45.912903 46.019096]\n"]}]}]}